# CFPNet-M: A Light-Weight Encoder-Decoder Based Network for Multimodal Biomedical Image Real-Time Segmentation
<div align=center><img src="https://github.com/AngeLouCN/CFPNet-Medicine/blob/main/results/Drive.jpg" width="500" height="215" alt="Result"/></div>
<div align=center><img src="https://github.com/AngeLouCN/CFPNet-Medicine/blob/main/results/ISBI.jpg" width="500" height="175" alt="Result"/></div>
<div align=center><img src="https://github.com/AngeLouCN/CFPNet-Medicine/blob/main/results/Infrared Breast.jpg" width="500" height="125" alt="Result"/></div>
<div align=center><img src="https://github.com/AngeLouCN/CFPNet-Medicine/blob/main/results/Cvc-ClinicDB.jpg" width="500" height="150" alt="Result"/></div>
<div align=center><img src="https://github.com/AngeLouCN/CFPNet-Medicine/blob/main/results/ISIC2018.jpg" width="500" height="150" alt="Result"/></div>
Currently, developments of deep learning techniques are providing instrumental to identify, classify, and quantify patterns in medical images. Segmentation is one of important applications in medical image analysis. In this regard, U-Net is the predominant approach to medical image segmentation tasks. However, we found that those U-Net based models have limitations in several aspects, for example, millions of parameters in the U-Net consuming considerable computation resource and memory, lack of global information, and missing some tough objects. Therefore, we applied two modifications to improve the U-Net model: 1) designed and added the dilated channel-wise CNN module, 2) simplified the U shape network. Based on these two modifications, we proposed a novel light-wight architecture – Channel-wise Feature Pyramid Network for Medicine (CFPNet-M). To evaluate our method, we selected five datasets with different modalities: thermography, electron microscopy, endoscopy, dermoscopy, and digital retinal images. And we compared its performance with several models having different parameter scales. This paper also involves our previous studies of DC-UNet and some commonly used light-weight neural networks. We applied the Tanimoto similarity instead of the Jaccard index for gray level image measurements. By comparison, CFPNet-M achieves a comparable segmentation results on all five medical datasets with only 0.65 million parameters, which is about 2% of U-Net, and 8.8 MB memory. Meanwhile, the inference speed can reach 80 FPS on a single RTX 2070Ti GPU with the 256×192 pixels input size.
